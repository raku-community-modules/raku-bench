#!/usr/bin/env perl

# ABSTRACT: Run benchmark timings for various Perl 5, NQP, and Perl 6 implementations

use 5.010;
use strict;
use warnings;
use Pod::Usage;
use Getopt::Long;
use Time::HiRes     'time';
use File::Temp      'tempfile';
use List::Util      'min', 'max';
use List::MoreUtils 'uniq';
use Capture::Tiny   'capture';
use DateTime;
use File::Basename;
use IO::File;
use FindBin;
use JSON;
use Cwd;

my %DEFAULT = (
               TEST_RUNS        => 2,   # times to run each test, taking best time
               MIN_STARTUP_RUNS => 10,  # minimum times to run startup time test
               ENOUGH_TIME      => 5.0, # minimum run time (seconds) to give clean timing data for scalable tests
              );
my @GROUPS    = qw( perl5 nqp perl6 );
my %VM        = (
                 perl5     => 'perl',
                 'node.js' => 'nodejs',
                 mono      => 'mono-sgen',
                 d8        => 'BENCH/../v8/out/native/d8',
                );
my $COMPILERS = do "$FindBin::Bin/compilers.pl";
my %TESTS = (
             e => do "$FindBin::Bin/microbenchmarks.pl",
             f => do "$FindBin::Bin/minibenchmarks.pl",
            );
my (@COMPILERS, @TESTS);

my %FORMATTER = (
                 json => \&summarize_results_json,
                );
my $START_CWD = cwd;


MAIN();

sub MAIN {
    # Canonify compiler and test configuration
    canonify_compilers();
    canonify_tests();

    # Process options and command line arguments
    my $main_opt = process_options_and_arguments();

    # Open outfile
    my $out    = $main_opt->{outfile};
    my $out_fh = $out eq '-' ? \*STDOUT : IO::File->new($out, '>')
        or die "Could not open outfile '$out': $!";

    # Record general test configuration and info
    my %config = (
                  default   => \%DEFAULT,
                  vm        => \%VM,
                  groups    => \@GROUPS,
                  compilers => \@COMPILERS,
                  tests     => \@TESTS,
                 );

    my %run    = (
                  start_time => time,
                  options    => $main_opt,
                  versions   => detect_versions(),
                 );

    # Run tests
    my $results = run_all_tests($main_opt);
    $run{end_time} = time;

    # Output results
    $main_opt->{formatter}->(\%config, \%run, $results, $out_fh);
    say "Benchmark data written to '$out'." if $out ne '-';
}

sub canonify_compilers {
    for my $group (@GROUPS) {
        for my $compiler (@{$COMPILERS->{$group}}) {
            $compiler->{group} = $group;
            push @COMPILERS, $compiler;
        }
    }
}

sub canonify_tests {
    for my $type (sort keys %TESTS) {
        for my $test (@{$TESTS{$type}}) {
            $test->{type}    = $type;
            $test->{enabled} = 1 unless exists $test->{enabled};
            $test->{scaling} = 'double' unless exists $test->{scaling};
            push @TESTS, $test;
        }
    }
}

sub process_options_and_arguments {
    my %opt;
    GetOptions(\%opt, 'help|h|?!', 'man!', 'list-variants!', 'list-tests!', 'verbose!',
                      'runs=i', 'enough-time=f', 'format=s', 'outfile=s', 'tests=s')
        or pod2usage(-verbose => 0);
    pod2usage(-verbose => 1) if $opt{help};
    pod2usage(-verbose => 2) if $opt{man};
    list_variants()          if $opt{'list-variants'};
    list_tests()             if $opt{'list-tests'};

    # Canonicalize outfile and output format
    $opt{outfile} //= 'bench-' . DateTime->today->ymd . '.json';
    my $suffix      = (fileparse($opt{outfile}, qr/\.[^.]+$/))[2] || '.';
    my $ext         = lc substr $suffix, 1;

    $opt{format}  //= exists $FORMATTER{$ext} ? $ext : 'text';
    $opt{format}    = lc $opt{format};
    my $formatter   = $FORMATTER{$opt{format}}
        or pod2usage(-msg => "Unknown output format '$opt{format}'");
    $opt{formatter} = $formatter;

    # Allow selecting a subset of available tests
    enable_only_tests(split ',' => $opt{tests}) if $opt{tests};

    # Allow selecting a subset of available compilers
    enable_only_compilers(@ARGV) if @ARGV;

    return \%opt;
}

sub list_variants {
    my     $format = "%-10s   %-8s   %-7s   %-6s\n";
    printf $format, qw( VARIANT COMPILER VM LANGUAGE );

    my @compilers = sort { $a->{name} cmp $b->{name} } @COMPILERS;
    for my $compiler (@compilers) {
        printf $format, @$compiler{qw( name compiler vm language )};
    }

    exit 0;
}

sub list_tests {
    print "$_->{name}\n" for @TESTS;
    exit 0;
}

sub enable_only_tests {
    my %enabled = map {($_ => 1)} @_;

    for my $test (@TESTS) {
        $test->{enabled} = 0 unless $enabled{$test->{name}};
    }
}

sub enable_only_compilers {
    my %enabled = map {($_ => 1)} @_;

    for my $compiler (@COMPILERS) {
        $compiler->{enabled} = 0 unless $enabled{$compiler->{name}};
    }

    # Catch mistakes
    my %known = map {($_->{name} => 1)} @COMPILERS;
    for my $enabled (@_) {
        die "Compiler variant '$enabled' is unknown!  To list compiler variants, use:\n    $0 --list-variants\n"
            unless $known{$enabled};
    }
}

sub detect_versions {
    say "Detecting versions ...";

    my %version;
    my $cwd = cwd;

    my @detect_git_rev = qw( git describe --always --dirty );

    for my $compiler (@COMPILERS) {
        next unless $compiler->{enabled};

        my $dir = $compiler->{dir} || $START_CWD;
        my @cmd = @{$compiler->{show_ver}};
        s/\bVM\b/$VM{$compiler->{vm}}/g for       @cmd;
        s/\bBENCH\b/$FindBin::Bin/g     for $dir, @cmd;

        chdir $dir;
        $version{$compiler->{name}} = -d '.git' ? `@detect_git_rev` : `@cmd`;
    }

    chdir $FindBin::Bin;
    $version{bench} = `@detect_git_rev`;

    chomp for values %version;

    chdir $cwd;
    return \%version;
}

# Checks if the currently checked out git rev contains all commits from
# ("is greater than or equal to") some other rev
sub git_rev_ge {
    my $ver = shift;

    return unless -d '.git';

    my $old_ver    = `git rev-parse $ver^0`;             chomp $old_ver;
    my $cur_ver    = `git rev-parse HEAD`;               chomp $cur_ver;
    my $merge_base = `git merge-base $old_ver $cur_ver`; chomp $merge_base;

    return $merge_base eq $old_ver;
}

sub run_all_tests {
    my ($opt) = @_;

    my $runs          = $opt->{runs} || $DEFAULT{TEST_RUNS};
    my $startup_runs  = max($runs, $DEFAULT{MIN_STARTUP_RUNS});
    my $overhead_runs = $startup_runs;
    my $enough_time   = $opt->{'enough-time'} || $DEFAULT{ENOUGH_TIME};
    my $empty_test    = $TESTS{e}[0];

    say "Measuring startup times ...";
    my $times   = time_all_compilers($empty_test, $startup_runs, 0, $enough_time, $opt->{verbose});
    my $startup = best_times($times);
    $startup->{$_} = $startup->{$_}{1} for keys %$startup;

    my @results;
    eval { run_tests(\@TESTS, \@results, $startup, $runs, $overhead_runs, $enough_time, $opt->{verbose}) };
    warn "\n$@\n" if $@;
    return \@results;
}

sub run_tests {
    my ($tests, $results, $startup, $runs, $overhead_runs, $enough_time, $verbose) = @_;

    for my $test (@$tests) {
        next unless $test->{enabled};

        my $name = $test->{name};
        say "Testing $name ...";

        my $raw_times = time_all_compilers($test, $runs, $overhead_runs, $enough_time, $verbose, $startup);
        my $best      = best_times($raw_times);
        my $cooked    = subtract_times($best, $startup);
        push @$results, {
                         name    => $name,
                         conf    => $test,
                         raw     => $raw_times,
                         best    => $best,
                         cooked  => $cooked,
                        };
    }
}

sub time_all_compilers {
    my ($test, $runs, $overhead_runs, $enough_time, $verbose, $startup) = @_;

    my $test_type = $test->{type};
    my $cwd       = cwd;
    my %times;

    for my $perl (@COMPILERS) {
        next unless $perl->{enabled};

        my $name = $perl->{name};
        my $skip = $test->{skip};
        if ($skip) {
            say("--> skipping"), next if ref $skip eq 'CODE'  && $skip->($perl);
            say("--> skipping"), next if ref $skip eq 'ARRAY' && grep { $_ eq $name } @$skip;
        }

        my $dir   = $perl->{dir} || $START_CWD;
        my $comp  = $perl->{"${test_type}_compile"} || [];
        my $run   = $perl->{"${test_type}_run"};
        my $group = $perl->{group};
        my $args  = $test->{$group} // next;
        my @args  = ref $args ? @$args : ($args);

        s/\bVM\b/$VM{$perl->{vm}}/g      for       @$comp, @$run, @args;
        s/\bBENCH\b/$FindBin::Bin/g      for $dir, @$comp, @$run, @args;
        s{\bDATA\b}{$FindBin::Bin/data}g for $dir, @$comp, @$run, @args;

        my @compile;
        if (@$comp) {
            # XXXX: This shift is a code smell ...
            @compile = (@$comp, shift @args);
        }
        my @run = (@$run, @args);

        if ($dir) {
            chdir $dir or die "Could not change to $name directory '$dir': $!";
        }

        my  @all_times;
        my  $scalable = $test->{scalable} // ((grep /\bSCALE\b/ => @run) ? 1 : 0);
        if ($scalable) {
            my $scale  = $test->{scale} || 1;
            my $lowest = 0;

            # Determine 0-scale time (mostly compile time)
            say '+++ Determining compile time for this test ...' if $verbose;
            my  $run_times = time_command(\@compile, \@run, $overhead_runs, 0, $verbose);
            if ($run_times) {
                say '+++ Running scaled timings for this test ...' if $verbose;
                push @all_times, @$run_times;
                my $min_run_time = min(map { $_->{time} } @$run_times);
                my $startup_time = $startup ? $startup->{$name} || 0 : 0;
                my $ignore_time  = max($startup_time, $min_run_time);

                # Run scaled timing loop
                while ($run_times && $lowest < $enough_time) {
                    $run_times = time_command(\@compile, \@run, $runs, $scale, $verbose) or last;
                    push @all_times, @$run_times;
                    $lowest  = min(map { $_->{time} } @$run_times);
                    $lowest -= $ignore_time;
                    $scale   = $test->{scaling} eq 'linear' ? $scale + 1
                                                            : $scale * 2;
                }
            }
        }
        else {
            my $run_times = time_command(\@compile, \@run, $runs, 1, $verbose);
            push @all_times, @$run_times if $run_times;
        }

        $times{$name} = \@all_times;
    }

    chdir $cwd;
    return \%times;
}

sub time_command {
    my ($compile, $run, $count, $scale, $verbose) = @_;

    say "... performing $count run" . ($count == 1 ? '' : 's') . " at scale $scale"
        if $verbose;

    my (@times, $status);
    for my $i (1 .. $count) {
        say "    $i" if $verbose;

        my @run = @$run;
        s/\bSCALE\b/$scale/g for @run;

        my $start = time;

        if (@$compile) {
            my ($out, $err) = capture { $status = system @$compile };
            if ($status) {
                die "Test's compile command terminated by SIGINT.\n" if ($status & 127) == 2;
                warn "Failed to run compile command: @$compile\n"
                     . (length $err ? "Error:\n$err\n" : '');
                return undef;
            }

            my ($fh, $filename) = tempfile(UNLINK => 1);
            print $fh $out;
            close $fh;
            s/\bCOMPILED\b/$filename/g for @run;
        }

        $status  = system @run;
        my $time = time - $start;
        push @times, { run => $i, scale => $scale, time => $time };
        if ($status) {
            die "Test's run command terminated by SIGINT.\n" if ($status & 127) == 2;
            warn "Failed to run command: @run\n";
            return undef;
        }
    }

    return \@times;
}

sub best_times {
    my $raw_times = shift;
    my %best;

    while (my ($perl, $times) = each %$raw_times) {
        my %runs_by_scale;
        for my $run (@$times) {
            push @{$runs_by_scale{$run->{scale}} ||= []}, $run;
        }

        my %best_by_scale;
        while (my ($scale, $runs) = each %runs_by_scale) {
            $best_by_scale{$scale} = min(map { $_->{time} } @$runs);
        }

        $best{$perl} = \%best_by_scale;
    }

    return \%best;
}

sub subtract_times {
    my ($orig, $offset) = @_;

    return $orig unless $offset;

    my %cooked;

    while (my ($perl, $by_scale) = each %$orig) {
        while (my ($scale, $time) = each %$by_scale) {
            my $adjusted = ($time || 0) - ($offset->{$perl} || 0);
               $adjusted = 0 if $adjusted < 0;
            $cooked{$perl}{$scale} = $adjusted;
        }
    }

    return \%cooked;
}

sub summarize_results_json {
    my ($config, $run, $times, $out_fh) = @_;

    my $style = 1;

    my $encoder = JSON->new->utf8->canonical->allow_unknown;
       $encoder->pretty if $style;

    my %info = (
                config => $config,
                run    => $run,
                times  => $times,
               );

    my $json = $encoder->encode(\%info);

    print $out_fh $json;
}


__END__

=head1 NAME

timeall -- Benchmark Perl-family compilers against each other


=head1 SYNOPSIS

    timeall [--help|-h|-?] [--man] [--list-variants] [--list-tests]
    timeall [--verbose] [--runs=2] [--enough-time=3.0]
            [--format=json] [--outfile=path/to/file.ext]
            [--tests=list,of,tests] [<enabled compiler variants>]

=head1 DESCRIPTION

This program benchmarks a number of implementations of Perl-family languages
against each other doing various simple tasks.  For a given task, each
language uses a similar algorithm, but written in the appropriate colloquial
style.  For a given language, all relevant implementations execute exactly
the same program for each task, or are marked as unable to process that task.

The simplest tasks are executed using each implementation's "evaluate a string
from the command line" option, generally C<-e> or C<-E>.  These attempt to
use nearly identical code across languages except for required syntax changes,
as with sigil variance/invariance or converting between builtin and
module-loaded functions.  When a language does not provide a given idiom
at all, that task is simply skipped by all implementations of that language.

More complex tasks are composed of matching scripts sorted into subdirectories
by language, optionally with additional command line arguments.  These larger
programs have somewhat more freedom to make use of language-specific idioms,
but care is taken that the basic algorithms and intrinsic complexity are still
the same.  Most (hopefully all) of these can be expressed in every language;
any failures are generally due to limitations of a particular implementation.

Once this script produces a file of timing information, the timing file can
be fed to the F<analyze> script to produce human-friendly summaries of the
timing data.

By default all known implementations of all known languages will be timed
running several iterations of every task, and the best time for each task and
implementation used.  To choose only a subset of the implementations, you may
specify a list of compiler variant names (e.g. C<p5.js_node> for Perlito5
targeting the Node JavaScript VM, or C<rakudo.nqp> for Rakudo running NQP
code instead of its native Perl 6 code) on the command line.  In this case,
only the specified variants will be enabled for that run.  To list the known
compiler variants, use the C<--list-variants> option.

To choose only particular tests to run, specify a comma-separated list of
test names with the C<--tests> option.  To see the list of known names, use
the C<--list-tests> option.


=head1 OPTIONS

=over 4

=item --help|-h|-?

Get basic help for this program

=item --man

Display this program's entire manpage

=item --list-variants

List all known compiler variants

=item --list-tests

List all known tests

=item --verbose

Display additional information when performing tests that can help when
determining when and how a compiler is breaking on a given test.

=item --runs=2

Set the number of times each test will be run using each compiler variant.
The benchmark code uses the best recorded time across all runs for each test
and compiler combination, so increasing the run count helps to avoid fluke
measurements and the effects of random background processes, but rapidly
reaches diminishing returns.  Many times it's more effective to just turn off
as many background processes (such as email clients) as possible while
benchmarking.

=item --enough-time=3.0

Set the amount of time a scalable test must run (not including startup and
compile time) before the timing data is considered "good enough", causing
F<timeall> to stop scaling up that test and go on to the next one.

=item --format=json

Format the summary output in a particular format.  If the C<--outfile> option
is set, then the default output format is based on the lowercased extension
of the output filename.  Otherwise the default (and currently only) format is
C<json>, which outputs the results in computer-friendly format suitable for
feeding to the F<analyze> program.

=item --outfile=path/to/file.ext|-

Write the summary report to a particular path and file, or to STDOUT if
C<--outfile> is set to C<-> (a single hyphen).  If this option is set and
C<--format> is not, then the summary format defaults to the lowercased
extension (F<ext> in F<path/to/file.ext>) of the C<--outfile>.  The default
C<--outfile> is F<bench-YYYY-MM-DD.json>, where F<YYYY-MM-DD> is today's date.

=item --tests=list,of,tests

Enable only a subset of the available tests (instead of the default of all
known tests), using a comma separated list of the test names.  To see the
list of known test names, use the C<--list-tests> option.

=back


=head1 AUTHOR

Geoffrey Broadwell


=cut
