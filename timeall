#!/usr/bin/env perl

# ABSTRACT: Run benchmark timings for various Perl 5, NQP, and Perl 6 implementations

use 5.010;
use strict;
use warnings;
use Pod::Usage;
use Getopt::Long;
use Time::HiRes     'time';
use File::Temp      'tempfile';
use List::Util      'min', 'max';
use List::MoreUtils 'uniq';
use Capture::Tiny   'capture';
use DateTime;
use File::Basename;
use IO::File;
use FindBin;
use JSON;
use Cwd;

my %DEFAULT = (
               TEST_RUNS          => 2,   # times to run each test, taking best time
               MIN_STARTUP_RUNS   => 10,  # minimum times to run startup time test
               ENOUGH_TIME        => 1.0, # minimum run time (seconds) to give clean timing data for scalable tests
               MIN_SCALING_POINTS => 3,   # minimum different points to test on each scaling curve
              );
my @GROUPS    = qw( perl5 nqp perl6 );
my %VM        = (
                 perl5     => 'perl',
                 'node.js' => 'nodejs',
                 mono      => 'mono-sgen',
                 d8        => 'BENCH/../v8/out/native/d8',
                );
my $COMPILERS = do "$FindBin::Bin/compilers.pl";
my %TESTS = (
             e => do "$FindBin::Bin/microbenchmarks.pl",
             f => do "$FindBin::Bin/minibenchmarks.pl",
            );
my (@COMPILERS, @TESTS);

my %FORMATTER = (
                 json => \&summarize_results_json,
                );
my $START_CWD = cwd;


MAIN();

sub MAIN {
    # Canonify compiler and test configuration
    canonify_compilers();
    canonify_tests();

    # Process options and command line arguments
    my $main_opt = process_options_and_arguments();

    # Open outfile
    my $out    = $main_opt->{outfile};
    my $out_fh = $out eq '-' ? \*STDOUT : IO::File->new($out, '>')
        or die "Could not open outfile '$out': $!";

    # Record general test configuration and info
    my %config = (
                  default   => \%DEFAULT,
                  vm        => \%VM,
                  groups    => \@GROUPS,
                  compilers => \@COMPILERS,
                  tests     => \@TESTS,
                 );

    my $bench_version = detect_versions();
    my %run    = (
                  start_time   => time,
                  options      => $main_opt,
                  versions     => { bench => $bench_version },
                 );

    # Run tests
    my ($results, $startup) = run_all_tests($main_opt);
    $run{end_time} = time;
    $run{startup}  = $startup;

    # Output results
    $main_opt->{formatter}->(\%config, \%run, $results, $out_fh);
    say "Benchmark data written to '$out'." if $out ne '-';
}

sub canonify_compilers {
    for my $group (@GROUPS) {
        for my $compiler (@{$COMPILERS->{$group}}) {
            $compiler->{group} = $group;
            push @COMPILERS, $compiler;
        }
    }
}

sub canonify_tests {
    for my $type (sort keys %TESTS) {
        for my $test (@{$TESTS{$type}}) {
            $test->{type}    = $type;
            $test->{enabled} = 1 unless exists $test->{enabled};
            $test->{scaling} = 'double' unless exists $test->{scaling};
            add_test_tags($test);
            push @TESTS, $test;
        }
    }
}

sub add_test_tags {
    my $test = shift;
    my %tags = map {( $_ => 1 )} @{$test->{tags} || []};

    my $type = $test->{type};
    my $size = $type eq 'e' ? 'micro' : 'mini';
    $tags{"type:$type"} = 1;
    $tags{"size:$size"} = 1;

    for my $lang (@GROUPS) {
        my $code = $test->{$lang};
        if (defined $code) {
            $tags{"has-lang:$lang"} = 1;

            my $text = ref $code ? "@$code" : $code;
            $tags{"scalable"} = 1 if $text =~ /\bSCALE\b/;
        }
    }

    $test->{tags} = [ sort keys %tags ];
}

sub tests_matching {
    my $query     = shift;
    my @terms     = split /,/ => $query;
    my @required  = grep /^(?!-)/ => @terms;
    my @forbidden = map { substr($_, 1) } grep /^-/ => @terms;

    my %known = map {( $_ => 1)} known_tags();
    for my $tag (@required) {
        die "Unknown required tag '$tag'!\n" unless $known{$tag};
    }
    for my $tag (@forbidden) {
        die "Unknown forbidden tag '$tag'!\n" unless $known{$tag};
    }

    my @matching;
    TEST: for my $test (@TESTS) {
        my $tags = $test->{tags};
        my %tags = map {( $_ => 1 )} @$tags;
        for (@forbidden) {
            next TEST if     $tags{$_};
        }
        for (@required) {
            next TEST unless $tags{$_};
        }

        push @matching, $test;
    }

    return @matching;
}

sub test_names_matching {
    return map { $_->{name} } tests_matching(@_);
}

sub known_tags {
    my %known;
    for my $test (@TESTS) {
        $known{$_} = 1 for @{$test->{tags}};
    }

    return sort keys %known;
}

sub process_options_and_arguments {
    my %opt;
    GetOptions(\%opt, 'help|h|?!', 'man!', 'verbose!', 'format=s', 'outfile=s',
                      'runs=i', 'enough-time=f', 'min-scaling-points=i',
                      'list-variants!', 'list-tests!', 'tests=s',
                      'list-tags!', 'list-tests-tagged=s', 'tests-tagged=s')
        or pod2usage(-verbose => 0);
    pod2usage(-verbose => 1) if $opt{help};
    pod2usage(-verbose => 2) if $opt{man};
    list_variants()          if $opt{'list-variants'};
    list_tags()              if $opt{'list-tags'};

    list_tests(tests_matching($opt{'list-tests-tagged'})) if defined $opt{'list-tests-tagged'};
    list_tests(@TESTS) if $opt{'list-tests'};

    # Canonicalize outfile and output format
    $opt{outfile} //= 'bench-' . DateTime->today->ymd . '.json';
    my $suffix      = (fileparse($opt{outfile}, qr/\.[^.]+$/))[2] || '.';
    my $ext         = lc substr $suffix, 1;

    $opt{format}  //= exists $FORMATTER{$ext} ? $ext : 'text';
    $opt{format}    = lc $opt{format};
    my $formatter   = $FORMATTER{$opt{format}}
        or pod2usage(-msg => "Unknown output format '$opt{format}'");
    $opt{formatter} = $formatter;

    # Allow selecting a subset of available tests
    enable_only_tests(split ',' => $opt{tests}) if $opt{tests};
    enable_only_tests(test_names_matching($opt{'tests-tagged'})) if $opt{'tests-tagged'};

    # Allow selecting a subset of available compilers
    enable_only_compilers(@ARGV) if @ARGV;

    return \%opt;
}

sub list_variants {
    my     $format = "%-13s   %-8s   %-7s   %-6s\n";
    printf $format, qw( VARIANT COMPILER VM LANGUAGE );

    my @compilers = sort { $a->{name} cmp $b->{name} } @COMPILERS;
    for my $compiler (@compilers) {
        printf $format, @$compiler{qw( name compiler vm language )};
    }

    exit 0;
}

sub list_tests {
    print "$_->{name}\n" for @_;
    exit 0;
}

sub list_tags {
    print "$_\n" for known_tags();
    exit 0;
}

sub enable_only_tests {
    my %enabled = map {($_ => 1)} @_;

    for my $test (@TESTS) {
        $test->{enabled} = 0 unless $enabled{$test->{name}};
    }
}

sub enable_only_compilers {
    my %enabled = map {($_ => 1)} @_;

    for my $compiler (@COMPILERS) {
        $compiler->{enabled} = 0 unless $enabled{$compiler->{name}};
    }

    # Catch mistakes
    my %known = map {($_->{name} => 1)} @COMPILERS;
    for my $enabled (@_) {
        die "Compiler variant '$enabled' is unknown!  To list compiler variants, use:\n    $0 --list-variants\n"
            unless $known{$enabled};
    }
}

sub detect_versions {
    say "Detecting versions ...";

    my $cwd = cwd;

    my @detect_git_rev     = qw( git describe --always --dirty );
    my @detect_commit_time = qw( git show -s --format=%ct HEAD );

    for my $compiler (@COMPILERS) {
        next unless $compiler->{enabled};

        my $dir = $compiler->{dir} || $START_CWD;
        my @cmd = @{$compiler->{show_ver}};
        s/\bVM\b/$VM{$compiler->{vm}}/g for       @cmd;
        s/\bBENCH\b/$FindBin::Bin/g     for $dir, @cmd;

        chdir $dir;
        my $name = $compiler->{name};
        if (-d '.git') {
            $compiler->{version}     = `@detect_git_rev`;
            $compiler->{commit_time} = `@detect_commit_time`;
            chomp($compiler->{version});
            chomp($compiler->{commit_time});
        }
        else {
            $compiler->{version} = `@cmd`;
            chomp($compiler->{version});
        }
    }

    chdir $FindBin::Bin;
    my $bench_version = `@detect_git_rev`;
    chomp($bench_version);

    chdir $cwd;
    return $bench_version;
}

# Checks if the currently checked out git rev contains all commits from
# ("is greater than or equal to") some other rev
sub git_rev_ge {
    my $ver = shift;

    return unless -d '.git';

    my $old_ver    = `git rev-parse $ver^0`;             chomp $old_ver;
    my $cur_ver    = `git rev-parse HEAD`;               chomp $cur_ver;
    my $merge_base = `git merge-base $old_ver $cur_ver`; chomp $merge_base;

    return $merge_base eq $old_ver;
}

sub run_all_tests {
    my ($opt) = @_;

    my $runs          = $opt->{runs} || $DEFAULT{TEST_RUNS};
    my $startup_runs  = max($runs, $DEFAULT{MIN_STARTUP_RUNS});
    my $overhead_runs = $startup_runs;
    my $enough_time   = $opt->{'enough-time'} || $DEFAULT{ENOUGH_TIME};
    my $scale_points  = $opt->{'min-scaling-points'} || $DEFAULT{MIN_SCALING_POINTS};
    my $empty_test    = $TESTS{e}[0];

    say "Measuring startup times ...";
    # If user aborts now, don't bother catching it; normal testing hasn't begun
    my $times   = time_all_compilers($empty_test, $startup_runs, 0, $enough_time, 0, $opt->{verbose});
    my $startup = best_times($times);
    $startup->{$_} = $startup->{$_}{1}{time} for keys %$startup;

    my @results;
    # Catch user aborts so that results for completed tests can be returned
    eval { run_tests(\@TESTS, \@results, $startup, $runs, $overhead_runs, $enough_time, $scale_points, $opt->{verbose}) };
    warn "\n$@\n" if $@;
    return (\@results, $startup);
}

sub run_tests {
    my ($tests, $results, $startup, $runs, $overhead_runs, $enough_time, $min_scaling_points, $verbose) = @_;

    my @enabled   = grep { $_->{enabled} } @$tests;
    my $testcount = @enabled;
    my $testnum   = 0;
    for my $test (@enabled) {
        $testnum++;
        my $name = $test->{name};
        say "$testnum/$testcount: Testing $name ...";

        # Let user aborts fall out to run_all_tests() so that the last test
        # timed won't have partial (and possibly misleading) timing data
        my $raw_times = time_all_compilers($test, $runs, $overhead_runs, $enough_time, $min_scaling_points, $verbose, $startup);
        my $best      = best_times($raw_times);
        push @$results, {
                         name    => $name,
                         conf    => $test,
                         raw     => $raw_times,
                         best    => $best,
                        };
    }
}

sub time_all_compilers {
    my ($test, $runs, $overhead_runs, $enough_time, $min_scaling_points, $verbose, $startup) = @_;

    my $test_type = $test->{type};
    my $cwd       = cwd;
    my %times;

    for my $comp (@COMPILERS) {
        next unless $comp->{enabled};

        my $name = $comp->{name};
        my $skip = $test->{skip};
        if ($skip) {
            say("--> skipping"), next if ref $skip eq 'CODE'  && $skip->($comp);
            say("--> skipping"), next if ref $skip eq 'ARRAY' && grep { $_ eq $name } @$skip;
        }

        my $dir     = $comp->{dir} || $START_CWD;
        my $compile = $comp->{"${test_type}_compile"} || [];
        my $run     = $comp->{"${test_type}_run"};
        my $group   = $comp->{group};
        my $args    = $test->{$group} // next;
        my @args    = ref $args ? @$args : ($args);

        s/\bVM\b/$VM{$comp->{vm}}/g      for       @$compile, @$run, @args;
        s/\bBENCH\b/$FindBin::Bin/g      for $dir, @$compile, @$run, @args;
        s{\bDATA\b}{$FindBin::Bin/data}g for $dir, @$compile, @$run, @args;
        if ($^O =~ /MSWin32/) {
            s/"/'/g for @$run, @args;
        }

        my @compile;
        if (@$compile) {
            # XXXX: This shift is a code smell ...
            @compile = (@$compile, shift @args);
        }
        my @run = (@$run, @args);

        if ($dir) {
            chdir $dir or die "Could not change to $name directory '$dir': $!";
        }

        my $is_code  = ref $test->{expected} eq 'CODE';
        my $expected = $is_code ?       $test->{expected}
                                : sub { $test->{expected} };

        my  @all_times;
        my  $scalable = $test->{scalable} // ((grep /\bSCALE\b/ => @run) ? 1 : 0);
        if ($scalable) {
            my $scale  = $test->{scale} || 1;
            my $work   = $test->{work}  || sub { $_[0] };
            my $lowest = 0;

            # Determine 0-scale time (mostly compile time)
            say '+++ Determining compile time for this test ...' if $verbose;
            my $run_times = time_command(\@compile, \@run, $overhead_runs, 0, 0, $expected->(0), $verbose);
            push @all_times, @{$run_times || []};
            if (!$run_times || grep { $_->{failed} } @$run_times) {
                warn "Compiler $name is failing at scale=0 for test $test->{name}, aborting remaining runs.\n";
                next;
            }

            say '+++ Running scaled timings for this test ...' if $verbose;
            my $min_run_time = min(map { $_->{time} } @$run_times);
            my $startup_time = $startup ? $startup->{$name} || 0 : 0;
            my $ignore_time  = max($startup_time, $min_run_time);

            # Run scaled timing loop
            my $scale_points = 0;
            while ($run_times && ($lowest < $enough_time || $scale_points < $min_scaling_points)) {
                $run_times = time_command(\@compile, \@run, $runs, $scale, $work->($scale), $expected->($scale), $verbose);
                push @all_times, @{$run_times || []};
                if (!$run_times || grep { $_->{failed} } @$run_times) {
                    warn "Compiler $name is failing at scale=$scale for test $test->{name}, aborting remaining runs.\n";
                    last;
                }
                $scale_points++;

                $lowest  = min(map { $_->{time} } @$run_times);
                $lowest -= $ignore_time;
                $scale   = $test->{scaling} eq 'linear' ? $scale + 1
                                                        : $scale * 2;
            }
        }
        else {
            my $run_times = time_command(\@compile, \@run, $runs, 1, 1, $expected->(1), $verbose);
            push @all_times, @{$run_times || []};
            if (!$run_times || grep { $_->{failed} } @$run_times) {
                warn "Compiler $name is failing for test $test->{name}, continuing to next compiler/test.\n";
                next;
            }
        }

        $times{$name} = \@all_times;
    }

    chdir $cwd;
    return \%times;
}

sub time_command {
    my ($compile, $run, $count, $scale, $work, $expected, $verbose) = @_;

    say "... performing $count run" . ($count == 1 ? '' : 's') . " at scale $scale (work $work)"
        if $verbose;

    my (@times, $status);
    for my $i (1 .. $count) {
        say "    $i" if $verbose;

        my @run = @$run;
        s/\bSCALE\b/$scale/g for @run;

        my $start = time;

        if (@$compile) {
            my ($out, $err, $status) = capture { system @$compile };
            my ($failed, $reason) = diagnose_capture($out, $err, $status);
            if ($failed) {
                my $run_info = {
                    run => $i, scale => $scale, work => $work, time => 0,
                    out => $out, err => $err, status => $status,
                    failed => $failed, reason => $reason,
                    command => $compile, phase => 'compile',
                };
                push @times, $run_info;

                my $msg = "Compile command $reason: @$compile\n";

                # User requested to abort testing
                if ($failed < 0) {
                    die $msg;
                }
                # Normal failures
                else {
                    warn $msg;
                    last;
                }
            }

            my ($fh, $filename) = tempfile(UNLINK => 1);
            print $fh $out;
            close $fh;
            s/\bCOMPILED\b/$filename/g for @run;
        }

        my ($out, $err, $status) = capture { system @run };
        my $time = time - $start;
        my ($failed, $reason) = diagnose_capture($out, $err, $status, $expected);

        my $run_info = {
            run => $i, scale => $scale, work => $work, time => $time,
            out => $out, err => $err, status => $status, phase => 'run',
            failed => $failed, reason => $reason, command => \@run,
        };
        push @times, $run_info;

        if ($failed) {
            my $msg = "Run command $reason: @run\n";

            # User requested to abort testing
            if ($failed < 0) {
                die $msg;
            }
            # Normal failures
            else {
                warn $msg;
                last;
            }
        }
    }

    return \@times;
}

sub diagnose_capture {
    my ($out, $err, $status, $expected) = @_;

    my $failed = 0;
    my $reason = '';

    if ($out =~ /Segmentation/i || $err =~ /Segmentation/i) {
        $failed = 1;
        $reason = 'segfaulted';
    }
    elsif ($status) {
        $failed = 1;
        if ($status < 0) {
            $reason = 'failed to spawn';
        }
        elsif (my $signal = $status & 127) {
            $reason = "received signal $signal";

            # Handle SIGINT specially as it indicates user intervention
            if ($signal == 2) {
                $failed = -1;
                $reason = 'terminated by SIGINT';
            }
        }
        else {
            my $exit = $status >> 8;
            $reason = "exited with exit status $exit";
        }
    }
    elsif (length $err) {
        $failed = 1;
        $reason = 'wrote to STDERR';
    }
    elsif (defined $expected && $expected ne $out) {
        $failed = 1;
        $reason = 'did not produce expected output';
    }

    return ($failed, $reason);
}

sub min_by(&@) {
    my $code = shift;

    return unless @_;
    my $min_item = shift;
    my $min_val  = do { local $_ = $min_item; &$code };

    for (@_) {
        my  $val = &$code;
        if ($val < $min_val) {
            $min_item = $_;
            $min_val  = $val;
        }
    }

    return $min_item;
}

sub best_times {
    my $raw_times = shift;
    my %best;

    while (my ($comp, $times) = each %$raw_times) {
        my %runs_by_scale;
        for my $run (@$times) {
            push @{$runs_by_scale{$run->{scale}} ||= []}, $run
                unless $run->{failed};
        }
        # If all runs failed, don't add the compiler to the best times at all
        next unless %runs_by_scale;

        my %best_by_scale;
        while (my ($scale, $runs) = each %runs_by_scale) {
            $best_by_scale{$scale} = min_by { $_->{time} } @$runs;
        }

        $best{$comp} = \%best_by_scale;
    }

    return \%best;
}

sub summarize_results_json {
    my ($config, $run, $times, $out_fh) = @_;

    my $style = 1;

    my $encoder = JSON->new->utf8->canonical->allow_unknown;
       $encoder->pretty if $style;

    my %info = (
                config => $config,
                run    => $run,
                times  => $times,
               );

    my $json = $encoder->encode(\%info);

    print $out_fh $json;
}


__END__

=head1 NAME

timeall -- Benchmark Perl-family compilers against each other


=head1 SYNOPSIS

    timeall [--help|-h|-?] [--man] [--list-variants] [--list-tests]
            [--list-tags] [--list-tests-tagged=required-tag,-forbidden-tag]
    timeall [--verbose] [--runs=2] [--enough-time=3.0]
            [--format=json] [--outfile=path/to/file.ext]
            [--tests=list,of,tests] [--tests-tagged=required,-forbidden]
            [<enabled compiler variants>]

=head1 DESCRIPTION

This program benchmarks a number of implementations of Perl-family languages
against each other doing various simple tasks.  For a given task, each
language uses a similar algorithm, but written in the appropriate colloquial
style.  For a given language, all relevant implementations execute exactly
the same program for each task, or are marked as unable to process that task.

The simplest tasks are executed using each implementation's "evaluate a string
from the command line" option, generally C<-e> or C<-E>.  These attempt to
use nearly identical code across languages except for required syntax changes,
as with sigil variance/invariance or converting between builtin and
module-loaded functions.  When a language does not provide a given idiom
at all, that task is simply skipped by all implementations of that language.

More complex tasks are composed of matching scripts sorted into subdirectories
by language, optionally with additional command line arguments.  These larger
programs have somewhat more freedom to make use of language-specific idioms,
but care is taken that the basic algorithms and intrinsic complexity are still
the same.  Most (hopefully all) of these can be expressed in every language;
any failures are generally due to limitations of a particular implementation.

Once this script produces a file of timing information, the timing file can
be fed to the F<analyze> script to produce human-friendly summaries of the
timing data.

By default all known implementations of all known languages will be timed
running several iterations of every task, and the best time for each task and
implementation used.  To choose only a subset of the implementations, you may
specify a list of compiler variant names (e.g. C<p5.js_node> for Perlito5
targeting the Node JavaScript VM, or C<rakudo.nqp> for Rakudo running NQP
code instead of its native Perl 6 code) on the command line.  In this case,
only the specified variants will be enabled for that run.  To list the known
compiler variants, use the C<--list-variants> option.

To choose only particular tests to run, specify a comma-separated list of
test names with the C<--tests> option.  To see the list of known names, use
the C<--list-tests> option.  To choose particular test sets by tag, use the
C<--tests-tagged> option; to see what tests will be chosen with a particular
tag query, use the C<--list-tests-tagged> option.


=head1 OPTIONS

=over 4

=item --help|-h|-?

Get basic help for this program.

=item --man

Display this program's entire manpage.

=item --list-variants

List all known compiler variants.

=item --list-tests

List all known tests.

=item --list-tags

List all known tags.

=item --list-tests-tagged=required-tag,-forbidden-tag

List tests according to a tag query, specifying which tags a test is
required to have and which tags it must B<not> have.  Tags should be
separated by commas, with no spaces.  Add a leading  C<-> (minus sign)
in front of any tags that must be disallowed; the default is to require
matching tests to have all listed tags.  This option merely lists
matching tests; to run matching tests, use the same query with the
C<--tests-tagged> option.

=item --verbose

Display additional information when performing tests that can help when
determining when and how a compiler is breaking on a given test.

=item --runs=2

Set the number of times each test will be run using each compiler variant.
The benchmark code uses the best recorded time across all runs for each test
and compiler combination, so increasing the run count helps to avoid fluke
measurements and the effects of random background processes, but rapidly
reaches diminishing returns.  Many times it's more effective to just turn off
as many background processes (such as email clients) as possible while
benchmarking.

=item --enough-time=1.0

Set the amount of time a scalable test must run (not including startup and
compile time) before the timing data is considered "good enough", causing
F<timeall> to stop scaling up that test and go on to the next one.

=item --min-scaling-points=3

Set the minimum number of different scale points a scalable test must run for
each compiler.  This minimum must be met regardless of the C<--enough-time>
setting, and makes sure that even when a compiler is performing very poorly
on a given test, enough different scales will be timed to get an idea what
the compiler's scaling curve looks like for that test.

=item --format=json

Format the summary output in a particular format.  If the C<--outfile> option
is set, then the default output format is based on the lowercased extension
of the output filename.  Otherwise the default (and currently only) format is
C<json>, which outputs the results in computer-friendly format suitable for
feeding to the F<analyze> program.

=item --outfile=path/to/file.ext|-

Write the summary report to a particular path and file, or to STDOUT if
C<--outfile> is set to C<-> (a single hyphen).  If this option is set and
C<--format> is not, then the summary format defaults to the lowercased
extension (F<ext> in F<path/to/file.ext>) of the C<--outfile>.  The default
C<--outfile> is F<bench-YYYY-MM-DD.json>, where F<YYYY-MM-DD> is today's date.

=item --tests=list,of,tests

Enable only a subset of the available tests (instead of the default of all
known tests), using a comma separated list of the test names.  To see the
list of known test names, use the C<--list-tests> option.

=item --list-tests-tagged=required-tag,-forbidden-tag

Enable only tests that match a tag query specifying which tags a test is
required to have and which tags it must B<not> have.  Tags should be
separated by commas, with no spaces.  Add a leading  C<-> (minus sign)
in front of any tag that must be disallowed; the default is to require
matching tests to have all listed tags.  To see which tests a tag query
will run, use the same query with the C<--list-tests-tagged> option.

=back


=head1 AUTHOR

Geoffrey Broadwell


=cut
